{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aaec2-bdb7-4a08-9377-0a2512c541d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings)\n",
    "from langchain.document_loaders import ConfluenceLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from atlassian import Confluence\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import getpass\n",
    "import json\n",
    "import pickle\n",
    "import uuid\n",
    "import chromadb\n",
    "import re\n",
    "from chromadb.config import Settings\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10e222-272a-435c-b1d7-dff81b21e262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = \n",
    "confluence_url = \n",
    "user = \n",
    "space_key = \n",
    "\n",
    "foundation_model = \"gpt-3.5-turbo\"\n",
    "vector_store = r\"./Documents/chroma_db/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a287fd9-757c-441f-8769-c1cc09e0d5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(tokens, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "key_dict = json.loads(content)\n",
    "atlassian_token = key_dict['atlassian']\n",
    "os.environ[\"OPENAI_API_KEY\"] = key_dict['openai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d47e861-79a1-49cb-8c35-d5b3e36c4454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confluence = Confluence(url=confluence_url,\n",
    "               username=user,\n",
    "               password=atlassian_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7e9d8-4afd-49b2-ae03-3aabfd056c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=foundation_model,\n",
    "                 temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7ab51-9ff9-4511-b36b-a05eb30aa683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = ConfluenceLoader(\n",
    "    url=confluence_url,\n",
    "    username = user,\n",
    "    api_key= atlassian_token)\n",
    "\n",
    "documents = loader.load(\n",
    "    space_key=space_key,\n",
    "    limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3ec8e-689f-4e64-8ab1-098bdd5cb028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    text = \" \".join([word for word in text.split() if word not in (stop)])\n",
    "    text = re.sub(\"(\\n+)\", \"\", text)\n",
    "    text = re.sub(\"(\\s){2,}\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87983556-3c2f-4ac3-a831-a76a35de9d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, _ in enumerate(documents):\n",
    "    documents[i].page_content = clean_text(documents[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1acce-937d-416e-99ec-c56c2ccfd4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save locally as a checkpoint\n",
    "with open('algo_confluence.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(documents, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92400c-9efc-4308-aa9a-955809168296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100,\n",
    "                                      chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=1000,\n",
    "                                  chunk_overlap=10,\n",
    "                                  encoding_name=\"cl100k_base\") #text-embedding-ada-002\n",
    "tokenized_text = token_splitter.split_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7f894-f1f0-446b-a765-62725e4a07a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example of confluence page metadata\n",
    "confluence.get_page_by_id('261470',\n",
    "                          expand=True,\n",
    "                          status=None,\n",
    "                          version=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea8b77-d2e1-4b6e-bf42-007e6439a767",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Embedding options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c497708-dea8-4cc0-9c37-e1a12ce0e0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 1. BERT (opensource)\n",
    "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\") \n",
    "\n",
    "## 2. OpenAI - $$$\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "##3. Instructor (instruction-Finetuned Text Embeddings) (opensource)\n",
    "# model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "# instruction = \"Represent the document for retrieval: \"\n",
    "# instruction_pairs = [[instruction, i.page_content] for i in tokenized_text]\n",
    "# customized_embeddings = model.encode(texts_with_instructions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea9e28-1743-4879-b9bd-969cce808881",
   "metadata": {},
   "source": [
    "## Set up vector DB to store embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5180cd6-ec5d-485b-9b63-13ccf078e542",
   "metadata": {},
   "source": [
    "#### Local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac3dba-9c28-412f-b609-63176b4a34f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if persist_directory  and os.path.exists(vector_store):\n",
    "#     vectordb = Chroma(persist_directory=vector_store, embedding_function=embedding)\n",
    "# else:\n",
    "vectordb = Chroma.from_documents(documents=tokenized_text, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec0d0f-62cb-4cf0-97cb-77b1b8ac56b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get sample key \n",
    "sample_key = vectordb.get()['ids'][0]\n",
    "print(sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf861e-268a-4f1b-b6c8-ae2666e386eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb.get(sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06a4f0-3506-43da-955d-26904a671752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb.get(sample_key, include=['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c5632-039c-4032-ab46-c54812ba7e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(vectordb.get(sample_key, include=['embeddings'])['embeddings'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1feab-f466-45a5-bcc4-d110b02890bf",
   "metadata": {},
   "source": [
    "#### Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb627834-09ba-4355-9f15-051f9558ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone git@github.com:chroma-core/chroma.git\n",
    "# docker-compose up -d --build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a8bd1-dcd2-48d9-8853-79825aaa3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or via docker\n",
    "\n",
    "client = chromadb.HttpClient(settings=Settings(allow_reset=True))\n",
    "client.reset()  # resets the database\n",
    "collection = client.create_collection(\"test_collection\")\n",
    "\n",
    "for doc in tokenized_text:\n",
    "    collection.add(\n",
    "        ids=[str(uuid.uuid1())], metadatas=doc.metadata, documents=doc.page_content\n",
    "    )\n",
    "\n",
    "# For langchain\n",
    "vectordb = Chroma(client=client,\n",
    "                  collection_name=\"test_collection\",\n",
    "                  embedding_function=embedding_function,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965fbbc1-cf8f-4fd8-96cb-f8b17216b35b",
   "metadata": {},
   "source": [
    "## Prompt engineering and querying LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e28818-ce3f-428d-bdc3-5691271a830a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\":4})\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675acfd3-9171-4ceb-b673-b58e294b54f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"You are a Confluence chatbot answering questions. \n",
    "                            Use the following pieces of context to answer the question at the end. \n",
    "                            If you don't know the answer, say that you don't know, don't try to make up an answer.\n",
    "\n",
    "                            {context}\n",
    "\n",
    "                            Question: {question}\n",
    "                            Helpful Answer:\n",
    "                            \"\"\"\n",
    "\n",
    "CUSTOMPROMPT = PromptTemplate(\n",
    "    template=custom_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa.combine_documents_chain.llm_chain.prompt = CUSTOMPROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9e5f5-c2a4-4430-86e1-6f4495d3fbb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Please explain how features are calculated in the lost sales project\"\n",
    "\n",
    "answer = qa.run(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2e6be-e21c-4847-a157-92d21252963b",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc60ea-915d-4d02-81d4-d29fff59ea5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"llm_name\": \"gpt-3.5-turbo\",\n",
    "    \"url\": 'https://c-b4web.atlassian.net/',\n",
    "    \"user\": 'jackm@cb4.com',\n",
    "    \"api_key\": atlassian_token,\n",
    "    \"space\": 'ALGO'\n",
    "}\n",
    "\n",
    "\n",
    "class ConfluenceQA:\n",
    "    def __init__(self,\n",
    "                config: dict={}):\n",
    "        self.config = config\n",
    "        self.embedding = self.init_embeddings()\n",
    "        self.llm_name = self.init_model()\n",
    "        self.loader = ConfluenceLoader(url=config['url'],\n",
    "                                       username = config['user'],\n",
    "                                       api_key= config['api_key'])\n",
    "        \n",
    "        self.vectordb = None\n",
    "        self.texts = None\n",
    "        self.retroever = None\n",
    "        self.qa = None\n",
    "        \n",
    "    def init_embeddings(self) -> None:\n",
    "        if 'embedding' in [i.lower() for i in self.config.keys()]:\n",
    "            return self.config['embedding']\n",
    "        else:\n",
    "            return OpenAIEmbeddings()\n",
    "        \n",
    "    def init_model(self) -> None:\n",
    "        \n",
    "        if 'llm_name' in [i.lower() for i in self.config.keys()]:\n",
    "            return ChatOpenAI(model_name=self.config['llm_name'],\n",
    "                              temperature=0)\n",
    "        else:\n",
    "            return ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
    "                              temperature=0)\n",
    "    \n",
    "    def get_chunk_documents(self) -> None:      \n",
    "        documents = self.loader.load(space_key=self.config['space_key'], \n",
    "                                     limit=100)\n",
    "\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=100,\n",
    "                                              chunk_overlap=0)\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        text_splitter = TokenTextSplitter(chunk_size=1000,\n",
    "                                          chunk_overlap=10,\n",
    "                                          encoding_name=\"cl100k_base\")  # This the encoding for text-embedding-ada-002\n",
    "        self.texts = text_splitter.split_documents(texts)\n",
    "    \n",
    "    def vector_db_confluence_docs(self, force_reload:bool= False) -> None:\n",
    "        self.vectordb = Chroma.from_documents(documents=self.texts,\n",
    "                                              embedding=self.embedding)\n",
    "        \n",
    "    def retreival_qa_chain(self):\n",
    "        self.retriever = self.vectordb.as_retriever(search_kwargs={\"k\":4})\n",
    "        self.qa = RetrievalQA.from_chain_type(llm=self.llm,\n",
    "                                              chain_type=\"stuff\",\n",
    "                                              retriever=self.retriever)\n",
    "        \n",
    "    def answer_confluence(self, question: str) -> str:\n",
    "        answer = self.qa.run(question)\n",
    "        return answer\n",
    "    \n",
    "    def run_qa_setup(self) -> None:\n",
    "        self.get_chunk_documents()\n",
    "        self.vector_db_confluence_docs()\n",
    "        self.qa()\n",
    "        \n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "        text = \" \".join([word for word in text.split() if word not in (stop)])\n",
    "        text = re.sub(\"(\\n+)\", \"\", text)\n",
    "        text = re.sub(\"(\\s){2,}\", \" \", text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289239a-04e2-4d97-82d7-1dd0c16fa15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"llm_name\": \"gpt-3.5-turbo\",\n",
    "    \"url\": 'https://c-b4web.atlassian.net/',\n",
    "    \"user\": 'jackm@cb4.com',\n",
    "    \"api_key\": atlassian_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fbc9c-687b-45ea-874e-cbcc1ed3148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confluence_qa = ConfluenceQA(config=config_dict)\n",
    "confluence_qa.run_qa_setup()\n",
    "result = confluence_qa.answer_confluence(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bb300-7e7d-4041-8379-bb0714bfd933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import the ConfluenceQA class\n",
    "from confluence_qa import ConfluenceQA\n",
    "\n",
    "try:\n",
    "    from hyperplane.utils import is_jhub\n",
    "    if is_jhub():\n",
    "        openaiKeyFile = '/root/.secret/openai_key.json'\n",
    "    else:\n",
    "        openaiKeyFile = '/etc/hyperplane/secrets/openai_key.json'\n",
    "    with open(openaiKeyFile) as f:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = json.load(f)['openai_key']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    load_dotenv()\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title='Q&A Bot for Confluence Page',\n",
    "    page_icon='âš¡',\n",
    "    layout='wide',\n",
    "    initial_sidebar_state='auto',\n",
    ")\n",
    "if \"config\" not in st.session_state:\n",
    "    st.session_state[\"config\"] = {}\n",
    "if \"confluence_qa\" not in st.session_state:\n",
    "    st.session_state[\"confluence_qa\"] = None\n",
    "\n",
    "@st.cache_resource\n",
    "def load_confluence(config):\n",
    "    # st.write(\"loading the confluence page\")\n",
    "    confluence_qa = ConfluenceQA(config=config)\n",
    "    confluence_qa.init_embeddings()\n",
    "    confluence_qa.init_models()\n",
    "    confluence_qa.vector_db_confluence_docs()\n",
    "    confluence_qa.retreival_qa_chain()\n",
    "    return confluence_qa\n",
    "\n",
    "with st.sidebar.form(key ='Form1'):\n",
    "    st.markdown('## Add your configs')\n",
    "    confluence_url = st.text_input(\"paste the confluence URL\", \"https://templates.atlassian.net/wiki/\")\n",
    "    username = st.text_input(label=\"confluence username\",\n",
    "                             help=\"leave blank if confluence page is public\",\n",
    "                             type=\"password\")\n",
    "    space_key = st.text_input(label=\"confluence space\",\n",
    "                             help=\"Space of Confluence\",\n",
    "                             value=\"RD\")\n",
    "    api_key = st.text_input(label=\"confluence api key\",\n",
    "                            help=\"leave blank if confluence page is public\",\n",
    "                            type=\"password\")\n",
    "    submitted1 = st.form_submit_button(label='Submit')\n",
    "\n",
    "    if submitted1 and confluence_url and space_key:\n",
    "        st.session_state[\"config\"] = {\n",
    "            \"persist_directory\": None,\n",
    "            \"confluence_url\": confluence_url,\n",
    "            \"username\": username if username != \"\" else None,\n",
    "            \"api_key\": api_key if api_key != \"\" else None,\n",
    "            \"space_key\": space_key,\n",
    "        }\n",
    "        with st.spinner(text=\"Ingesting Confluence...\"):\n",
    "            ### Hardcoding for https://templates.atlassian.net/wiki/ and space RD to avoid multiple OpenAI calls.\n",
    "            config = st.session_state[\"config\"]\n",
    "            if  config[\"confluence_url\"] == \"https://templates.atlassian.net/wiki/\" and config[\"space_key\"] ==\"RD\":\n",
    "                config[\"persist_directory\"] = \"chroma_db\"\n",
    "            st.session_state[\"config\"] = config\n",
    "\n",
    "            st.session_state[\"confluence_qa\"]  = load_confluence(st.session_state[\"config\"])\n",
    "        st.write(\"Confluence Space Ingested\")\n",
    "        \n",
    "\n",
    "st.title(\"Confluence Q&A Demo\")\n",
    "\n",
    "question = st.text_input('Ask a question', \"How do I make a space public?\")\n",
    "\n",
    "if st.button('Get Answer', key='button2'):\n",
    "    with st.spinner(text=\"Asking LLM...\"):\n",
    "        confluence_qa = st.session_state.get(\"confluence_qa\")\n",
    "        if confluence_qa is not None:\n",
    "            result = confluence_qa.answer_confluence(question)\n",
    "            st.write(result)\n",
    "        else:\n",
    "            st.write(\"Please load Confluence page first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fc69f-f62d-4b39-8093-be19f76b6b8f",
   "metadata": {},
   "source": [
    "# zero shot topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d780d3-d29f-4a5d-b4a3-b31cee3aaed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "zeroshot_topic_list = [\"Lost sales\", \"Forecast\", \"C-retail\"]\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    min_topic_size=15,\n",
    "    zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.85,\n",
    "    representation_model=KeyBERTInspired()\n",
    ")\n",
    "\n",
    "with open(r'../algo_confluence_text.pkl', 'rb') as text:\n",
    "    docs = pickle.load(text)\n",
    "    \n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc2d1c-7954-4745-a447-98ec90fe7d16",
   "metadata": {},
   "source": [
    "## DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ad141-051c-487b-95c3-7037593eeb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(tokens, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "key_dict = json.loads(content)\n",
    "os.environ[\"OPENAI_API_KEY\"] = key_dict['openai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ac248-2e2d-40d0-890c-72cd11c79771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea658f2-8670-48de-9234-3dd9de8a3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680dbab-054e-4b6a-bcc3-5654d5b67b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5bd0f-9ee3-48f4-a9cc-aef781665eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask any question you like to this simple RAG program.\n",
    "my_question = \"What castle did David Gregory inherit?\"\n",
    "\n",
    "# Get the prediction. This contains `pred.context` and `pred.answer`.\n",
    "pred = compiled_rag(my_question)\n",
    "\n",
    "# Print the contexts and the answer.\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
